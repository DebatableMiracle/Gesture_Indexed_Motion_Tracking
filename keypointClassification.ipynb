{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e7ee234-31f2-4558-ad4d-5c5dfdba741c",
   "metadata": {},
   "source": [
    "# Loading Models and Defining Paths and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07344a68-68c4-44c4-8dd3-329f2921c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b36f4f-dbb0-4352-ab84-0abcc9363604",
   "metadata": {},
   "source": [
    "Paths in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b13b85fb-c839-4021-b5a9-8cb491c2471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"C:\\\\Users\\\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\datasets\\keypoint.csv\"\n",
    "model_save_path = \"C:\\\\Users\\\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\"\n",
    "tflite_save_path = \"C:\\\\Users\\\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier_tf.tflite\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f79dd08f-481f-4f3c-94dc-771c8b815efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1fe99-4623-4c02-8507-29c3e568bcdf",
   "metadata": {},
   "source": [
    "Dataset Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "452fc515-bb63-4272-9ac8-8f8dea278df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = np.loadtxt(dataset, delimiter = ',', dtype = 'float32', usecols = list(range(1, (21*2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dc82c70-0401-4ed8-84b4-e1b0c26f2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter = ',', dtype = 'int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c90f03b1-7129-4b7b-822e-99cf346d1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_dataset, y_dataset, train_size = 0.75, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8f87e-40e6-48b4-a43a-bcc869da423f",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54952823-5b59-4436-9f97-29fbd4e6f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usual model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input((21*2)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(16, activation = 'relu'),\n",
    "    layers.Dense(num_classes, activation = 'softmax')\n",
    "])\n",
    "#smaller model\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Input((21 * 2, )),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(20, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(10, activation='relu'),\n",
    "#     tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "# ])\n",
    "#cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4345d31-af6e-423c-8b22-f2554a062909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout (Dropout)           (None, 42)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1376      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1989 (7.77 KB)\n",
      "Trainable params: 1989 (7.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cccd961-6f0f-4d0b-8611-b70c052100be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose = 1, save_weights_only = False)\n",
    "es_callback = keras.callbacks.EarlyStopping(patience = 30, verbose = 1)\n",
    "Callbacks = [cp_callback, es_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9410602f-600f-4081-874c-b0fecedf0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = \"rmsprop\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = ['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00676f1-b161-43a5-9c38-097e1ae544de",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66fe6252-0382-4c73-926c-dbf23a3b5de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60/72 [========================>.....] - ETA: 0s - loss: 1.5010 - accuracy: 0.3143\n",
      "Epoch 1: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 1.4865 - accuracy: 0.3272 - val_loss: 1.3001 - val_accuracy: 0.5558\n",
      "Epoch 2/1000\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 1.3095 - accuracy: 0.4429\n",
      "Epoch 2: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3050 - accuracy: 0.4433 - val_loss: 1.1051 - val_accuracy: 0.6937\n",
      "Epoch 3/1000\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 1.1822 - accuracy: 0.5109\n",
      "Epoch 3: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.1657 - accuracy: 0.5234 - val_loss: 0.9376 - val_accuracy: 0.7089\n",
      "Epoch 4/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 1.0822 - accuracy: 0.5490\n",
      "Epoch 4: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0640 - accuracy: 0.5606 - val_loss: 0.7940 - val_accuracy: 0.7842\n",
      "Epoch 5/1000\n",
      "46/72 [==================>...........] - ETA: 0s - loss: 1.0065 - accuracy: 0.5866\n",
      "Epoch 5: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9838 - accuracy: 0.6064 - val_loss: 0.6959 - val_accuracy: 0.8271\n",
      "Epoch 6/1000\n",
      "55/72 [=====================>........] - ETA: 0s - loss: 0.9136 - accuracy: 0.6420\n",
      "Epoch 6: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9158 - accuracy: 0.6398 - val_loss: 0.6177 - val_accuracy: 0.8238\n",
      "Epoch 7/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.8681 - accuracy: 0.6422\n",
      "Epoch 7: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.8580 - accuracy: 0.6517 - val_loss: 0.5567 - val_accuracy: 0.8409\n",
      "Epoch 8/1000\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 0.8304 - accuracy: 0.6704\n",
      "Epoch 8: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.8168 - accuracy: 0.6799 - val_loss: 0.5124 - val_accuracy: 0.8574\n",
      "Epoch 9/1000\n",
      "31/72 [===========>..................] - ETA: 0s - loss: 0.8321 - accuracy: 0.6643\n",
      "Epoch 9: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.8081 - accuracy: 0.6821 - val_loss: 0.4789 - val_accuracy: 0.8759\n",
      "Epoch 10/1000\n",
      "44/72 [=================>............] - ETA: 0s - loss: 0.7808 - accuracy: 0.6967\n",
      "Epoch 10: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7790 - accuracy: 0.6983 - val_loss: 0.4534 - val_accuracy: 0.8726\n",
      "Epoch 11/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.7382 - accuracy: 0.7149\n",
      "Epoch 11: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7149 - val_loss: 0.4297 - val_accuracy: 0.8818\n",
      "Epoch 12/1000\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.7155 - accuracy: 0.7281\n",
      "Epoch 12: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.7118 - accuracy: 0.7265 - val_loss: 0.4077 - val_accuracy: 0.8865\n",
      "Epoch 13/1000\n",
      "57/72 [======================>.......] - ETA: 0s - loss: 0.6854 - accuracy: 0.7283\n",
      "Epoch 13: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.7340 - val_loss: 0.3815 - val_accuracy: 0.8957\n",
      "Epoch 14/1000\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 0.7028 - accuracy: 0.7281\n",
      "Epoch 14: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.7296 - val_loss: 0.3745 - val_accuracy: 0.8957\n",
      "Epoch 15/1000\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.6853 - accuracy: 0.7331\n",
      "Epoch 15: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.7404 - val_loss: 0.3623 - val_accuracy: 0.8990\n",
      "Epoch 16/1000\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 0.6642 - accuracy: 0.7454\n",
      "Epoch 16: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.7452 - val_loss: 0.3502 - val_accuracy: 0.9036\n",
      "Epoch 17/1000\n",
      "58/72 [=======================>......] - ETA: 0s - loss: 0.6413 - accuracy: 0.7570\n",
      "Epoch 17: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7575 - val_loss: 0.3299 - val_accuracy: 0.9149\n",
      "Epoch 18/1000\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 0.6184 - accuracy: 0.7582\n",
      "Epoch 18: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.7567 - val_loss: 0.3167 - val_accuracy: 0.9294\n",
      "Epoch 19/1000\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.6178 - accuracy: 0.7666\n",
      "Epoch 19: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7679 - val_loss: 0.3065 - val_accuracy: 0.9254\n",
      "Epoch 20/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.6315 - accuracy: 0.7610\n",
      "Epoch 20: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.7683 - val_loss: 0.2895 - val_accuracy: 0.9413\n",
      "Epoch 21/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.6072 - accuracy: 0.7644\n",
      "Epoch 21: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.7712 - val_loss: 0.2965 - val_accuracy: 0.9208\n",
      "Epoch 22/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.6089 - accuracy: 0.7742\n",
      "Epoch 22: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7765 - val_loss: 0.2798 - val_accuracy: 0.9333\n",
      "Epoch 23/1000\n",
      "57/72 [======================>.......] - ETA: 0s - loss: 0.6060 - accuracy: 0.7782\n",
      "Epoch 23: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.7809 - val_loss: 0.2755 - val_accuracy: 0.9320\n",
      "Epoch 24/1000\n",
      "60/72 [========================>.....] - ETA: 0s - loss: 0.6036 - accuracy: 0.7708\n",
      "Epoch 24: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.7725 - val_loss: 0.2838 - val_accuracy: 0.9234\n",
      "Epoch 25/1000\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.5765 - accuracy: 0.7860\n",
      "Epoch 25: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7859 - val_loss: 0.2673 - val_accuracy: 0.9327\n",
      "Epoch 26/1000\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 0.5674 - accuracy: 0.7891\n",
      "Epoch 26: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7932 - val_loss: 0.2564 - val_accuracy: 0.9399\n",
      "Epoch 27/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.5611 - accuracy: 0.7957\n",
      "Epoch 27: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7938 - val_loss: 0.2525 - val_accuracy: 0.9380\n",
      "Epoch 28/1000\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.5785 - accuracy: 0.7803\n",
      "Epoch 28: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.7839 - val_loss: 0.2563 - val_accuracy: 0.9340\n",
      "Epoch 29/1000\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.5559 - accuracy: 0.7960\n",
      "Epoch 29: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7963 - val_loss: 0.2418 - val_accuracy: 0.9432\n",
      "Epoch 30/1000\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.5462 - accuracy: 0.7967\n",
      "Epoch 30: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.7967 - val_loss: 0.2479 - val_accuracy: 0.9373\n",
      "Epoch 31/1000\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 0.5481 - accuracy: 0.8067\n",
      "Epoch 31: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.8020 - val_loss: 0.2404 - val_accuracy: 0.9439\n",
      "Epoch 32/1000\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.5481 - accuracy: 0.7927\n",
      "Epoch 32: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7958 - val_loss: 0.2307 - val_accuracy: 0.9452\n",
      "Epoch 33/1000\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.5384 - accuracy: 0.8000\n",
      "Epoch 33: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.8000 - val_loss: 0.2423 - val_accuracy: 0.9287\n",
      "Epoch 34/1000\n",
      "56/72 [======================>.......] - ETA: 0s - loss: 0.5089 - accuracy: 0.8158\n",
      "Epoch 34: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.8106 - val_loss: 0.2263 - val_accuracy: 0.9413\n",
      "Epoch 35/1000\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.5031 - accuracy: 0.8176\n",
      "Epoch 35: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.8088 - val_loss: 0.2347 - val_accuracy: 0.9333\n",
      "Epoch 36/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.5243 - accuracy: 0.8030\n",
      "Epoch 36: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.8079 - val_loss: 0.2206 - val_accuracy: 0.9432\n",
      "Epoch 37/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.5261 - accuracy: 0.8007\n",
      "Epoch 37: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.8057 - val_loss: 0.2276 - val_accuracy: 0.9399\n",
      "Epoch 38/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.5160 - accuracy: 0.8157\n",
      "Epoch 38: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.8141 - val_loss: 0.2277 - val_accuracy: 0.9314\n",
      "Epoch 39/1000\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 0.4892 - accuracy: 0.8108\n",
      "Epoch 39: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.8099 - val_loss: 0.2075 - val_accuracy: 0.9525\n",
      "Epoch 40/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.8046\n",
      "Epoch 40: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.8046 - val_loss: 0.2158 - val_accuracy: 0.9426\n",
      "Epoch 41/1000\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.5164 - accuracy: 0.8068\n",
      "Epoch 41: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.8068 - val_loss: 0.2205 - val_accuracy: 0.9432\n",
      "Epoch 42/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.5167 - accuracy: 0.8088\n",
      "Epoch 42: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.8125 - val_loss: 0.2192 - val_accuracy: 0.9465\n",
      "Epoch 43/1000\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 0.4938 - accuracy: 0.8177\n",
      "Epoch 43: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.8185 - val_loss: 0.2089 - val_accuracy: 0.9459\n",
      "Epoch 44/1000\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 0.4866 - accuracy: 0.8157\n",
      "Epoch 44: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8167 - val_loss: 0.2002 - val_accuracy: 0.9465\n",
      "Epoch 45/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4954 - accuracy: 0.8216\n",
      "Epoch 45: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.8211 - val_loss: 0.2115 - val_accuracy: 0.9406\n",
      "Epoch 46/1000\n",
      "62/72 [========================>.....] - ETA: 0s - loss: 0.5030 - accuracy: 0.8120\n",
      "Epoch 46: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.8134 - val_loss: 0.2078 - val_accuracy: 0.9386\n",
      "Epoch 47/1000\n",
      "58/72 [=======================>......] - ETA: 0s - loss: 0.4772 - accuracy: 0.8187\n",
      "Epoch 47: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.8207 - val_loss: 0.2006 - val_accuracy: 0.9492\n",
      "Epoch 48/1000\n",
      "57/72 [======================>.......] - ETA: 0s - loss: 0.4921 - accuracy: 0.8243\n",
      "Epoch 48: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.8266 - val_loss: 0.2095 - val_accuracy: 0.9465\n",
      "Epoch 49/1000\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.4856 - accuracy: 0.8191\n",
      "Epoch 49: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.8198 - val_loss: 0.2018 - val_accuracy: 0.9465\n",
      "Epoch 50/1000\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.4813 - accuracy: 0.8262\n",
      "Epoch 50: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.8284 - val_loss: 0.2013 - val_accuracy: 0.9439\n",
      "Epoch 51/1000\n",
      "55/72 [=====================>........] - ETA: 0s - loss: 0.4877 - accuracy: 0.8168\n",
      "Epoch 51: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.8172 - val_loss: 0.1923 - val_accuracy: 0.9452\n",
      "Epoch 52/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.4815 - accuracy: 0.8257\n",
      "Epoch 52: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.8264 - val_loss: 0.1991 - val_accuracy: 0.9446\n",
      "Epoch 53/1000\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4816 - accuracy: 0.8275\n",
      "Epoch 53: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.8275 - val_loss: 0.1940 - val_accuracy: 0.9452\n",
      "Epoch 54/1000\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 0.4612 - accuracy: 0.8375\n",
      "Epoch 54: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8334 - val_loss: 0.1994 - val_accuracy: 0.9465\n",
      "Epoch 55/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4780 - accuracy: 0.8272\n",
      "Epoch 55: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.8253 - val_loss: 0.1920 - val_accuracy: 0.9479\n",
      "Epoch 56/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4737 - accuracy: 0.8315\n",
      "Epoch 56: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8315 - val_loss: 0.1892 - val_accuracy: 0.9525\n",
      "Epoch 57/1000\n",
      "57/72 [======================>.......] - ETA: 0s - loss: 0.4349 - accuracy: 0.8396\n",
      "Epoch 57: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8376 - val_loss: 0.1798 - val_accuracy: 0.9531\n",
      "Epoch 58/1000\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.4581 - accuracy: 0.8281\n",
      "Epoch 58: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8255 - val_loss: 0.1800 - val_accuracy: 0.9591\n",
      "Epoch 59/1000\n",
      "59/72 [=======================>......] - ETA: 0s - loss: 0.4676 - accuracy: 0.8350\n",
      "Epoch 59: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.8339 - val_loss: 0.1659 - val_accuracy: 0.9637\n",
      "Epoch 60/1000\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 0.4601 - accuracy: 0.8375\n",
      "Epoch 60: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.8372 - val_loss: 0.1834 - val_accuracy: 0.9518\n",
      "Epoch 61/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.4676 - accuracy: 0.8330\n",
      "Epoch 61: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8372 - val_loss: 0.1799 - val_accuracy: 0.9531\n",
      "Epoch 62/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4482 - accuracy: 0.8367\n",
      "Epoch 62: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.8383 - val_loss: 0.1816 - val_accuracy: 0.9558\n",
      "Epoch 63/1000\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.4745 - accuracy: 0.8350\n",
      "Epoch 63: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.8282 - val_loss: 0.1935 - val_accuracy: 0.9531\n",
      "Epoch 64/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4428 - accuracy: 0.8379\n",
      "Epoch 64: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8372 - val_loss: 0.1807 - val_accuracy: 0.9505\n",
      "Epoch 65/1000\n",
      "29/72 [===========>..................] - ETA: 0s - loss: 0.4471 - accuracy: 0.8400\n",
      "Epoch 65: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.8365 - val_loss: 0.1766 - val_accuracy: 0.9558\n",
      "Epoch 66/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4367 - accuracy: 0.8364\n",
      "Epoch 66: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8326 - val_loss: 0.1879 - val_accuracy: 0.9479\n",
      "Epoch 67/1000\n",
      "33/72 [============>.................] - ETA: 0s - loss: 0.4424 - accuracy: 0.8423\n",
      "Epoch 67: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8378 - val_loss: 0.1808 - val_accuracy: 0.9545\n",
      "Epoch 68/1000\n",
      "61/72 [========================>.....] - ETA: 0s - loss: 0.4358 - accuracy: 0.8461\n",
      "Epoch 68: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8449 - val_loss: 0.1753 - val_accuracy: 0.9564\n",
      "Epoch 69/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4262 - accuracy: 0.8491\n",
      "Epoch 69: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8447 - val_loss: 0.1829 - val_accuracy: 0.9479\n",
      "Epoch 70/1000\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.4464 - accuracy: 0.8363\n",
      "Epoch 70: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8389 - val_loss: 0.1674 - val_accuracy: 0.9558\n",
      "Epoch 71/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.4594 - accuracy: 0.8444\n",
      "Epoch 71: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8462 - val_loss: 0.1680 - val_accuracy: 0.9571\n",
      "Epoch 72/1000\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.4374 - accuracy: 0.8390\n",
      "Epoch 72: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.8409 - val_loss: 0.1670 - val_accuracy: 0.9597\n",
      "Epoch 73/1000\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.4323 - accuracy: 0.8428\n",
      "Epoch 73: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8433 - val_loss: 0.1734 - val_accuracy: 0.9545\n",
      "Epoch 74/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4485 - accuracy: 0.8455\n",
      "Epoch 74: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.8495 - val_loss: 0.1704 - val_accuracy: 0.9591\n",
      "Epoch 75/1000\n",
      "62/72 [========================>.....] - ETA: 0s - loss: 0.4517 - accuracy: 0.8382\n",
      "Epoch 75: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8403 - val_loss: 0.1709 - val_accuracy: 0.9518\n",
      "Epoch 76/1000\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 0.4227 - accuracy: 0.8547\n",
      "Epoch 76: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8537 - val_loss: 0.1647 - val_accuracy: 0.9584\n",
      "Epoch 77/1000\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.4312 - accuracy: 0.8447\n",
      "Epoch 77: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8438 - val_loss: 0.1733 - val_accuracy: 0.9551\n",
      "Epoch 78/1000\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.4283 - accuracy: 0.8458\n",
      "Epoch 78: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8471 - val_loss: 0.1787 - val_accuracy: 0.9525\n",
      "Epoch 79/1000\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.4444 - accuracy: 0.8438\n",
      "Epoch 79: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.8436 - val_loss: 0.1826 - val_accuracy: 0.9545\n",
      "Epoch 80/1000\n",
      "29/72 [===========>..................] - ETA: 0s - loss: 0.4393 - accuracy: 0.8475\n",
      "Epoch 80: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8521 - val_loss: 0.1700 - val_accuracy: 0.9505\n",
      "Epoch 81/1000\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 0.4362 - accuracy: 0.8391\n",
      "Epoch 81: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8405 - val_loss: 0.1726 - val_accuracy: 0.9558\n",
      "Epoch 82/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4160 - accuracy: 0.8508\n",
      "Epoch 82: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8488 - val_loss: 0.1654 - val_accuracy: 0.9584\n",
      "Epoch 83/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4211 - accuracy: 0.8494\n",
      "Epoch 83: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8475 - val_loss: 0.1631 - val_accuracy: 0.9617\n",
      "Epoch 84/1000\n",
      "61/72 [========================>.....] - ETA: 0s - loss: 0.4319 - accuracy: 0.8476\n",
      "Epoch 84: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.8462 - val_loss: 0.1639 - val_accuracy: 0.9637\n",
      "Epoch 85/1000\n",
      "56/72 [======================>.......] - ETA: 0s - loss: 0.4311 - accuracy: 0.8496\n",
      "Epoch 85: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8473 - val_loss: 0.1711 - val_accuracy: 0.9551\n",
      "Epoch 86/1000\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.4052 - accuracy: 0.8656\n",
      "Epoch 86: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8594 - val_loss: 0.1665 - val_accuracy: 0.9584\n",
      "Epoch 87/1000\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.4381 - accuracy: 0.8459\n",
      "Epoch 87: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8462 - val_loss: 0.1765 - val_accuracy: 0.9518\n",
      "Epoch 88/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4142 - accuracy: 0.8461\n",
      "Epoch 88: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8493 - val_loss: 0.1605 - val_accuracy: 0.9624\n",
      "Epoch 89/1000\n",
      "64/72 [=========================>....] - ETA: 0s - loss: 0.4152 - accuracy: 0.8479\n",
      "Epoch 89: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8510 - val_loss: 0.1640 - val_accuracy: 0.9630\n",
      "Epoch 90/1000\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.4205 - accuracy: 0.8537\n",
      "Epoch 90: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8596 - val_loss: 0.1612 - val_accuracy: 0.9597\n",
      "Epoch 91/1000\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.4078 - accuracy: 0.8469\n",
      "Epoch 91: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8438 - val_loss: 0.1596 - val_accuracy: 0.9637\n",
      "Epoch 92/1000\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.4341 - accuracy: 0.8425\n",
      "Epoch 92: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8484 - val_loss: 0.1698 - val_accuracy: 0.9564\n",
      "Epoch 93/1000\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 0.4024 - accuracy: 0.8551\n",
      "Epoch 93: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8546 - val_loss: 0.1665 - val_accuracy: 0.9604\n",
      "Epoch 94/1000\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 0.4084 - accuracy: 0.8573\n",
      "Epoch 94: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8581 - val_loss: 0.1602 - val_accuracy: 0.9637\n",
      "Epoch 95/1000\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.4260 - accuracy: 0.8502\n",
      "Epoch 95: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8506 - val_loss: 0.1842 - val_accuracy: 0.9531\n",
      "Epoch 96/1000\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.4038 - accuracy: 0.8591\n",
      "Epoch 96: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8568 - val_loss: 0.1728 - val_accuracy: 0.9525\n",
      "Epoch 97/1000\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.4009 - accuracy: 0.8483\n",
      "Epoch 97: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8504 - val_loss: 0.1751 - val_accuracy: 0.9545\n",
      "Epoch 98/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4060 - accuracy: 0.8581\n",
      "Epoch 98: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8581 - val_loss: 0.1656 - val_accuracy: 0.9538\n",
      "Epoch 99/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.4132 - accuracy: 0.8569\n",
      "Epoch 99: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8572 - val_loss: 0.1600 - val_accuracy: 0.9571\n",
      "Epoch 100/1000\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3980 - accuracy: 0.8596\n",
      "Epoch 100: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8596 - val_loss: 0.1642 - val_accuracy: 0.9591\n",
      "Epoch 101/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4004 - accuracy: 0.8626\n",
      "Epoch 101: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8627 - val_loss: 0.1586 - val_accuracy: 0.9637\n",
      "Epoch 102/1000\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.4064 - accuracy: 0.8555\n",
      "Epoch 102: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8563 - val_loss: 0.1653 - val_accuracy: 0.9630\n",
      "Epoch 103/1000\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4117 - accuracy: 0.8517\n",
      "Epoch 103: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8517 - val_loss: 0.1642 - val_accuracy: 0.9591\n",
      "Epoch 104/1000\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 0.4044 - accuracy: 0.8544\n",
      "Epoch 104: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8565 - val_loss: 0.1681 - val_accuracy: 0.9512\n",
      "Epoch 105/1000\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.3720 - accuracy: 0.8607\n",
      "Epoch 105: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8618 - val_loss: 0.1662 - val_accuracy: 0.9525\n",
      "Epoch 106/1000\n",
      "46/72 [==================>...........] - ETA: 0s - loss: 0.4081 - accuracy: 0.8618\n",
      "Epoch 106: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8583 - val_loss: 0.1582 - val_accuracy: 0.9644\n",
      "Epoch 107/1000\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 0.3921 - accuracy: 0.8644\n",
      "Epoch 107: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8620 - val_loss: 0.1512 - val_accuracy: 0.9611\n",
      "Epoch 108/1000\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.3933 - accuracy: 0.8615\n",
      "Epoch 108: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8625 - val_loss: 0.1627 - val_accuracy: 0.9578\n",
      "Epoch 109/1000\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.3743 - accuracy: 0.8626\n",
      "Epoch 109: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8607 - val_loss: 0.1716 - val_accuracy: 0.9564\n",
      "Epoch 110/1000\n",
      "57/72 [======================>.......] - ETA: 0s - loss: 0.4142 - accuracy: 0.8522\n",
      "Epoch 110: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8521 - val_loss: 0.1827 - val_accuracy: 0.9479\n",
      "Epoch 111/1000\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.4004 - accuracy: 0.8551\n",
      "Epoch 111: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8568 - val_loss: 0.1710 - val_accuracy: 0.9578\n",
      "Epoch 112/1000\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 0.4006 - accuracy: 0.8541\n",
      "Epoch 112: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8537 - val_loss: 0.1840 - val_accuracy: 0.9485\n",
      "Epoch 113/1000\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.3819 - accuracy: 0.8684\n",
      "Epoch 113: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.8675 - val_loss: 0.1480 - val_accuracy: 0.9657\n",
      "Epoch 114/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.4086 - accuracy: 0.8576\n",
      "Epoch 114: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8627 - val_loss: 0.1611 - val_accuracy: 0.9584\n",
      "Epoch 115/1000\n",
      "47/72 [==================>...........] - ETA: 0s - loss: 0.4067 - accuracy: 0.8531\n",
      "Epoch 115: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8561 - val_loss: 0.1605 - val_accuracy: 0.9578\n",
      "Epoch 116/1000\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 0.4035 - accuracy: 0.8587\n",
      "Epoch 116: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8587 - val_loss: 0.1527 - val_accuracy: 0.9696\n",
      "Epoch 117/1000\n",
      "60/72 [========================>.....] - ETA: 0s - loss: 0.3698 - accuracy: 0.8747\n",
      "Epoch 117: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8695 - val_loss: 0.1751 - val_accuracy: 0.9531\n",
      "Epoch 118/1000\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.4075 - accuracy: 0.8527\n",
      "Epoch 118: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8524 - val_loss: 0.1611 - val_accuracy: 0.9611\n",
      "Epoch 119/1000\n",
      "59/72 [=======================>......] - ETA: 0s - loss: 0.3687 - accuracy: 0.8716\n",
      "Epoch 119: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8662 - val_loss: 0.1621 - val_accuracy: 0.9630\n",
      "Epoch 120/1000\n",
      "50/72 [===================>..........] - ETA: 0s - loss: 0.3863 - accuracy: 0.8591\n",
      "Epoch 120: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8601 - val_loss: 0.1580 - val_accuracy: 0.9637\n",
      "Epoch 121/1000\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.3835 - accuracy: 0.8648\n",
      "Epoch 121: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8662 - val_loss: 0.1502 - val_accuracy: 0.9657\n",
      "Epoch 122/1000\n",
      "57/72 [======================>.......] - ETA: 0s - loss: 0.3880 - accuracy: 0.8657\n",
      "Epoch 122: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8642 - val_loss: 0.1698 - val_accuracy: 0.9578\n",
      "Epoch 123/1000\n",
      "57/72 [======================>.......] - ETA: 0s - loss: 0.3818 - accuracy: 0.8629\n",
      "Epoch 123: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8631 - val_loss: 0.1633 - val_accuracy: 0.9617\n",
      "Epoch 124/1000\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8627\n",
      "Epoch 124: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8627 - val_loss: 0.1574 - val_accuracy: 0.9604\n",
      "Epoch 125/1000\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8693\n",
      "Epoch 125: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8693 - val_loss: 0.1682 - val_accuracy: 0.9545\n",
      "Epoch 126/1000\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.3862 - accuracy: 0.8638\n",
      "Epoch 126: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8678 - val_loss: 0.1594 - val_accuracy: 0.9630\n",
      "Epoch 127/1000\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.3817 - accuracy: 0.8712\n",
      "Epoch 127: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8675 - val_loss: 0.1538 - val_accuracy: 0.9657\n",
      "Epoch 128/1000\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 0.3803 - accuracy: 0.8565\n",
      "Epoch 128: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8594 - val_loss: 0.1703 - val_accuracy: 0.9531\n",
      "Epoch 129/1000\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 0.3876 - accuracy: 0.8611\n",
      "Epoch 129: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8647 - val_loss: 0.1669 - val_accuracy: 0.9604\n",
      "Epoch 130/1000\n",
      "49/72 [===================>..........] - ETA: 0s - loss: 0.3644 - accuracy: 0.8712\n",
      "Epoch 130: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8691 - val_loss: 0.1652 - val_accuracy: 0.9558\n",
      "Epoch 131/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.8640\n",
      "Epoch 131: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8640 - val_loss: 0.1721 - val_accuracy: 0.9531\n",
      "Epoch 132/1000\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.3756 - accuracy: 0.8712\n",
      "Epoch 132: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8684 - val_loss: 0.1635 - val_accuracy: 0.9650\n",
      "Epoch 133/1000\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.3888 - accuracy: 0.8624\n",
      "Epoch 133: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8634 - val_loss: 0.1698 - val_accuracy: 0.9564\n",
      "Epoch 134/1000\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.3811 - accuracy: 0.8704\n",
      "Epoch 134: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8660 - val_loss: 0.1758 - val_accuracy: 0.9551\n",
      "Epoch 135/1000\n",
      "54/72 [=====================>........] - ETA: 0s - loss: 0.3854 - accuracy: 0.8669\n",
      "Epoch 135: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8689 - val_loss: 0.1777 - val_accuracy: 0.9525\n",
      "Epoch 136/1000\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.3787 - accuracy: 0.8636\n",
      "Epoch 136: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8693 - val_loss: 0.1671 - val_accuracy: 0.9597\n",
      "Epoch 137/1000\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.3758 - accuracy: 0.8682\n",
      "Epoch 137: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8678 - val_loss: 0.1619 - val_accuracy: 0.9611\n",
      "Epoch 138/1000\n",
      "52/72 [====================>.........] - ETA: 0s - loss: 0.3862 - accuracy: 0.8654\n",
      "Epoch 138: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8700 - val_loss: 0.1546 - val_accuracy: 0.9630\n",
      "Epoch 139/1000\n",
      "48/72 [===================>..........] - ETA: 0s - loss: 0.3625 - accuracy: 0.8685\n",
      "Epoch 139: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8642 - val_loss: 0.1847 - val_accuracy: 0.9512\n",
      "Epoch 140/1000\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 0.3860 - accuracy: 0.8623\n",
      "Epoch 140: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8616 - val_loss: 0.1690 - val_accuracy: 0.9597\n",
      "Epoch 141/1000\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.3755 - accuracy: 0.8665\n",
      "Epoch 141: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8664 - val_loss: 0.1629 - val_accuracy: 0.9604\n",
      "Epoch 142/1000\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.3784 - accuracy: 0.8675\n",
      "Epoch 142: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8684 - val_loss: 0.1835 - val_accuracy: 0.9498\n",
      "Epoch 143/1000\n",
      "55/72 [=====================>........] - ETA: 0s - loss: 0.3706 - accuracy: 0.8651\n",
      "Epoch 143: saving model to C:\\Users\\anubh\\Desktop\\Hand gesture recognition\\hand gesture recognition with mediapipe\\models\\keypoint_classifier.keras\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8680 - val_loss: 0.1722 - val_accuracy: 0.9558\n",
      "Epoch 143: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2887efd1850>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs = 1000,\n",
    "          batch_size = 64,\n",
    "          validation_data = (x_test, y_test),\n",
    "          callbacks = Callbacks,\n",
    "         )          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b4d321-89fe-439b-9e25-882179c0f529",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0691b1c-8de3-4a47-a2b1-a2b83d48aed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1722 - accuracy: 0.9558\n"
     ]
    }
   ],
   "source": [
    "val_loss ,val_acc  = model.evaluate(x_test, y_test, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238329e1-68e5-481a-8d80-e5ae7d1c66b8",
   "metadata": {},
   "source": [
    "Day 1: We get an accuracy of 98.41% on the test data which is kinda good so like get\n",
    "\n",
    "Day 2: We get 98.58% but at 185 epochs compared to 127 at day 127 epochs with the same model\n",
    "\n",
    "Day 2.1: We get 96.49% at 204 epochs. AI is taking over.\n",
    "\n",
    "Day 3: We get 97.66% at 214 epochs. Data leakage is real. Altho very sad that the max accuracy died down.\n",
    "\n",
    "Day 4: 96.83% with a model of 60-70% the parameters.\n",
    "\n",
    "Day 5: Accuracy 95.58% for 143 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a494311-b020-4922-9952-f8fd1dc9d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f118eaa3-c25a-4100-9255-7657bcf52d58",
   "metadata": {},
   "source": [
    "Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e53e881c-69d9-4b36-9fe1-1f82f7e08403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n",
      "[4.9251937e-03 2.5286367e-02 9.6941662e-01 6.4205874e-06 3.6543031e-04]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "predict_result = model.predict(np.array([x_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dad867-c573-4c96-86f6-b2406b66e1cb",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43062674-381d-48be-be18-10bc2bebfcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "382fc5b5-082a-49e7-8d93-aa3ef0ffd14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 985us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.99      0.91      0.95       387\n",
      "           2       0.89      0.98      0.93       325\n",
      "           3       0.85      1.00      0.92        77\n",
      "           4       0.98      0.97      0.98       322\n",
      "\n",
      "    accuracy                           0.96      1515\n",
      "   macro avg       0.94      0.96      0.95      1515\n",
      "weighted avg       0.96      0.96      0.96      1515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_confusion_matrix(y_true, y_pred, report = True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred,labels = labels)\n",
    "\n",
    "    df_cmx = pd.DataFrame(cmx_data, index = labels, columns = labels)\n",
    "    fig, ax = plt.subplots(figsize =(7,6))\n",
    "    sns.heatmap(df_cmx, annot= True, fmt= 'g', square = False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "\n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(Y_pred, axis = 1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a7bf0-5493-4050-b27e-10308bc3005e",
   "metadata": {},
   "source": [
    "# Converting model to TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0634125-25b8-4689-a43c-d560e2181269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcbd95e2-130f-4990-b91f-df628b5548a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\anubh\\AppData\\Local\\Temp\\tmpm0x2de_m\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\anubh\\AppData\\Local\\Temp\\tmpm0x2de_m\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "429679a9-bef0-4569-9732-1dafcb14b734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6144"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c67d0d-5a06-4eca-9bed-8ad45d0fafd7",
   "metadata": {},
   "source": [
    "# Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57efbe88",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path = tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ea40253-03cb-46a7-8ffd-c6641553fb6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# get I/O tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c50125c5-ab4f-43fd-93ce-3431359797b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([x_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5241b0-8ef9-4d83-a0e8-4d05d92f368f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "535725d3-1869-41e7-b212-b5fccf9902a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "329cb9dd-f38f-44e2-90e1-eb78284f7b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0335680e-03 2.5201643e-02 9.6938872e-01 6.0693078e-06 3.7006958e-04]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e03740-811f-4efc-bfc6-bd6fa4fbe301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf17355-97ba-44c4-8f20-86c73ecf284c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
